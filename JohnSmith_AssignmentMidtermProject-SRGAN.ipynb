{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3387a5f",
   "metadata": {
    "id": "c3387a5f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from keras import Input\n",
    "from keras.applications import VGG19\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import BatchNormalization, Activation, LeakyReLU, Add, Dense\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import random\n",
    "from numpy import asarray\n",
    "from itertools import repeat\n",
    "\n",
    "import imageio\n",
    "from imageio import imread\n",
    "from PIL import Image\n",
    "from skimage.transform import resize as imresize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the path to the train directory\n",
    "train_dir = \"/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/train/\"\n",
    "\n",
    "# Create the val directory\n",
    "val_dir = \"/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/val/\"\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Define the split percentage\n",
    "split_pct = 0.3\n",
    "\n",
    "# Create subdirectories in train and val directories for DME and DRUSEN\n",
    "for subdir in ['DME', 'DRUSEN']:\n",
    "    os.makedirs(os.path.join(train_dir, subdir), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, subdir), exist_ok=True)\n",
    "\n",
    "    # Get a list of file names for this subdirectory\n",
    "    file_names = os.listdir(os.path.join(train_dir, subdir))\n",
    "\n",
    "    # Shuffle the list of file names\n",
    "    random.shuffle(file_names)\n",
    "\n",
    "    # Split the file names into train and val sets\n",
    "    split_idx = int(len(file_names) * (1 - split_pct))\n",
    "    train_files = file_names[:split_idx]\n",
    "    val_files = file_names[split_idx:]\n",
    "\n",
    "    # Move the files into the appropriate directories\n",
    "    for file_name in train_files:\n",
    "        src_path = os.path.join(train_dir, subdir, file_name)\n",
    "        dest_path = os.path.join(train_dir, subdir, file_name)\n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "    for file_name in val_files:\n",
    "        src_path = os.path.join(train_dir, subdir, file_name)\n",
    "        dest_path = os.path.join(val_dir, subdir, file_name)\n",
    "        shutil.move(src_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6277fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "TRAIN_PATH = r'/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/train/'\n",
    "VAL_PATH = r'/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/val/'\n",
    "TEST_PATH = r'/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/test/'\n",
    "data_path = TRAIN_PATH\n",
    "\n",
    "epochs = 150\n",
    "\n",
    "# batch size equals to 8 (due to RAM limits)\n",
    "batch_size = 8\n",
    "\n",
    "# define the shape of low resolution image (LR) \n",
    "low_resolution_shape = (32, 32, 3)\n",
    "\n",
    "# define the shape of high resolution image (HR) \n",
    "high_resolution_shape = (128, 128, 3)\n",
    "\n",
    "# optimizer for discriminator, generator \n",
    "common_optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# use seed for reproducible results\n",
    "SEED = 2020 \n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a path to image data as an argument\n",
    "def get_train_images(data_path):\n",
    "    \n",
    "    # Define the two classes of images we're looking for\n",
    "    CLASSES = ['DME', 'DRUSEN']\n",
    "    \n",
    "    # Create an empty list to store image file paths\n",
    "    image_list = []\n",
    "\n",
    "    # Loop through each class of images\n",
    "    for class_type in CLASSES:\n",
    "        # Use the glob module to find all image files within the folder for that class\n",
    "        # and add the resulting list of file paths to the image_list using the extend method\n",
    "        image_list.extend(glob.glob(data_path + class_type + '/*'))\n",
    "    \n",
    "    # Return the complete list of image file paths\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = get_train_images(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046277ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Image list\n",
    "#image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c72e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a list of image file paths as an argument\n",
    "def find_img_dims(image_list):\n",
    "    \n",
    "    # Initialize empty lists to store minimum and maximum image sizes\n",
    "    min_size = []\n",
    "    max_size = []\n",
    "    \n",
    "    # Loop through each image in the list\n",
    "    for i in range(len(image_list)):\n",
    "        # Open the image file using the Image module from PIL\n",
    "        im = Image.open(image_list[i])\n",
    "        # Add the minimum and maximum dimensions of the image to their respective lists\n",
    "        min_size.append(min(im.size))\n",
    "        max_size.append(max(im.size))\n",
    "    \n",
    "    # Return the overall minimum and maximum image dimensions as a tuple\n",
    "    return min(min_size), max(max_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7740d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get min/max image sizes\n",
    "\n",
    "image_list = get_train_images(data_path)\n",
    "min_size, max_size = find_img_dims(image_list)\n",
    "print('The min and max image dims are {} and {} respectively.'\n",
    "      .format(min_size, max_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "TRAIN_PATH = r'/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/train/'\n",
    "data_path = TRAIN_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082c0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "src_folder = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/train'\n",
    "dst_folder = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/original_train_images'\n",
    "\n",
    "shutil.copytree(src_folder, dst_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdc3fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes two images as input\n",
    "def compute_psnr(original_image, generated_image):\n",
    "    \n",
    "    # Convert the input images to TensorFlow tensors with dtype float32\n",
    "    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n",
    "    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n",
    "    \n",
    "    # Use the TensorFlow image module to compute the peak signal-to-noise ratio (PSNR) between the two images\n",
    "    # Set the maximum value of the images to 1.0\n",
    "    psnr = tf.image.psnr(original_image, generated_image, max_val=1.0)\n",
    "\n",
    "    # Compute the mean PSNR value across all image pixels\n",
    "    # axis=None indicates to compute the mean over all dimensions of the tensor\n",
    "    # keepdims=False specifies to reduce the dimensions of the output tensor\n",
    "    # name=None specifies not to use a custom name for the operation\n",
    "    return tf.math.reduce_mean(psnr, axis=None, keepdims=False, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afb66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psnr(psnr):\n",
    "    \n",
    "    psnr_means = psnr['psnr_quality']\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(psnr_means)    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('PSNR') \n",
    "    plt.title('PSNR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c13f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes two images as input\n",
    "def compute_ssim(original_image, generated_image):\n",
    "    \n",
    "    # Convert the input images to TensorFlow tensors with dtype float32\n",
    "    original_image = tf.convert_to_tensor(original_image, dtype=tf.float32)\n",
    "    generated_image = tf.convert_to_tensor(generated_image, dtype=tf.float32)\n",
    "    \n",
    "    # Use the TensorFlow image module to compute the structural similarity (SSIM) index between the two images\n",
    "    # Set the maximum value of the images to 1.0 and specify the filter size, filter sigma, and k1/k2 constants\n",
    "    ssim = tf.image.ssim(original_image, generated_image, max_val=1.0, filter_size=11,\n",
    "                          filter_sigma=1.5, k1=0.01, k2=0.03)\n",
    "\n",
    "    # Compute the mean SSIM value across all image pixels\n",
    "    # axis=None indicates to compute the mean over all dimensions of the tensor\n",
    "    # keepdims=False specifies to reduce the dimensions of the output tensor\n",
    "    # name=None specifies not to use a custom name for the operation\n",
    "    return tf.math.reduce_mean(ssim, axis=None, keepdims=False, name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ssim(ssim):\n",
    "    \n",
    "    ssim_means = ssim['ssim_quality']\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(ssim_means)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('SSIM')\n",
    "    plt.title('SSIM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8ba1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(losses):\n",
    "\n",
    "    d_loss = losses['d_history']\n",
    "    g_loss = losses['g_history']\n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(d_loss, label=\"Discriminator loss\")\n",
    "    plt.plot(g_loss, label=\"Generator loss\")\n",
    "    \n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(\"Loss\")    \n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81a4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(image_list, batch_size, high_resolution_shape, low_resolution_shape):\n",
    "    \n",
    "    \"\"\"\n",
    "    Pre-process a batch of training images\n",
    "    \"\"\"\n",
    "    \n",
    "    # image_list is the list of all images\n",
    "    # ransom sample a batch of images\n",
    "    images_batch = np.random.choice(image_list, size=batch_size)\n",
    "    \n",
    "    lr_images = []\n",
    "    hr_images = []\n",
    "    \n",
    "\n",
    "    for img in images_batch:\n",
    "  \n",
    "        #img1 = imread(img, as_gray=False, pilmode='RGB')\n",
    "        img1 = imread(img, pilmode='RGB')\n",
    "        img1 = img1.astype(np.float32)\n",
    "        \n",
    "        # change the size     \n",
    "        img1_high_resolution = imresize(img1, high_resolution_shape)\n",
    "        img1_low_resolution = imresize(img1, low_resolution_shape)\n",
    "                \n",
    "\n",
    "        # do a random horizontal flip\n",
    "        if np.random.random() < 0.5:\n",
    "            img1_high_resolution = np.fliplr(img1_high_resolution)\n",
    "            img1_low_resolution = np.fliplr(img1_low_resolution)\n",
    "       \n",
    "        hr_images.append(img1_high_resolution)\n",
    "        lr_images.append(img1_low_resolution)\n",
    "        \n",
    "   \n",
    "    # convert lists into numpy ndarrays\n",
    "    return np.array(hr_images), np.array(lr_images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7a2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(original_image, lr_image, sr_image, path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Save LR, HR (original) and generated SR\n",
    "    images in one panel \n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3, figsize=(10, 6))\n",
    "\n",
    "    images = [original_image, lr_image, sr_image]\n",
    "    titles = ['HR', 'LR','SR - generated']\n",
    "\n",
    "    for idx,img in enumerate(images):\n",
    "        # (X + 1)/2 to scale back from [-1,1] to [0,1]\n",
    "        ax[idx].imshow((img + 1)/2.0, cmap='gray')\n",
    "        ax[idx].axis(\"off\")\n",
    "    for idx, title in enumerate(titles):    \n",
    "        ax[idx].set_title('{}'.format(title))\n",
    "        \n",
    "    plt.savefig(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def residual_block(x):\n",
    "\n",
    " #   filters = [64, 64]\n",
    " #   kernel_size = 3\n",
    " #   strides = 1\n",
    " #   padding = \"same\"\n",
    " #   momentum = 0.8\n",
    " #   activation = \"relu\"\n",
    "\n",
    " #   res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    " #   res = Activation(activation=activation)(res)\n",
    " #   res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    " #   res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n",
    " #   res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    # Adjust shape of input x to match shape of res for adding\n",
    " #   if x.shape[-1] != res.shape[-1]:\n",
    " #       x = Conv2D(filters=filters[-1], kernel_size=1, strides=strides, padding=padding)(x)\n",
    " #       x = BatchNormalization(momentum=momentum)(x)\n",
    "\n",
    " #   res = Add()([res, x])\n",
    " #   res = Activation(activation=activation)(res)\n",
    "    \n",
    " #   return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e44079",
   "metadata": {},
   "source": [
    "The above commented out code was a block I originally ran but get shaping issues that I could not resolve. Got the program running with the below block but due to other issues being resolved. But did not want to run again. Above block may be a more correct implementation of the residual block; that's why it is left in, just commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1725f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x):\n",
    "\n",
    "    filters = [64, 64]\n",
    "    kernel_size = 3\n",
    "    strides = 1\n",
    "    padding = \"same\"\n",
    "    momentum = 0.8\n",
    "    activation = \"relu\"\n",
    "\n",
    "    res = Conv2D(filters=filters[0], kernel_size=kernel_size, strides=strides, padding=padding)(x)\n",
    "    res = Activation(activation=activation)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Conv2D(filters=filters[1], kernel_size=kernel_size, strides=strides, padding=padding)(res)\n",
    "    res = BatchNormalization(momentum=momentum)(res)\n",
    "\n",
    "    res = Add()([res, x])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    \n",
    "    # use 16 residual blocks in generator\n",
    "    residual_blocks = 16\n",
    "    momentum = 0.8\n",
    "    \n",
    "    # input LR dimension: 4x downsample of HR\n",
    "    input_shape = (32, 32, 3)\n",
    "    \n",
    "    # input for the generator\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # pre-residual block: conv layer before residual blocks \n",
    "    gen1 = Conv2D(filters=64, kernel_size=9, strides=1, padding='same', activation='relu')(input_layer)\n",
    "    \n",
    "    # add 16 residual blocks\n",
    "    res = residual_block(gen1)\n",
    "    for i in range(residual_blocks - 1):\n",
    "        res = residual_block(res)\n",
    "    \n",
    "    # post-residual block: conv and batch-norm layer after residual blocks\n",
    "    gen2 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(res)\n",
    "    gen2 = BatchNormalization(momentum=momentum)(gen2)\n",
    "    \n",
    "    # take the sum of pre-residual block(gen1) and post-residual block(gen2)\n",
    "    gen3 = Add()([gen2, gen1])\n",
    "    \n",
    "    # upsampling\n",
    "    gen4 = UpSampling2D(size=2)(gen3)\n",
    "    gen4 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen4)\n",
    "    gen4 = Activation('relu')(gen4)\n",
    "    \n",
    "    # upsampling\n",
    "    gen5 = UpSampling2D(size=2)(gen4)\n",
    "    gen5 = Conv2D(filters=256, kernel_size=3, strides=1, padding='same')(gen5)\n",
    "    gen5 = Activation('relu')(gen5)\n",
    "    \n",
    "    # conv layer at the output\n",
    "    gen6 = Conv2D(filters=3, kernel_size=9, strides=1, padding='same')(gen5)\n",
    "    output = Activation('tanh')(gen6)\n",
    "    \n",
    "    # model \n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='generator')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0004c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f77b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    \n",
    "    # define hyperparameters\n",
    "    leakyrelu_alpha = 0.2\n",
    "    momentum = 0.8\n",
    "    \n",
    "    # the input is the HR shape\n",
    "    input_shape = (128, 128, 3)\n",
    "    \n",
    "    # input layer for discriminator\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    \n",
    "    # 8 convolutional layers with batch normalization  \n",
    "    dis1 = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    dis1 = LeakyReLU(alpha=leakyrelu_alpha)(dis1)\n",
    "\n",
    "    dis2 = Conv2D(filters=64, kernel_size=3, strides=2, padding='same')(dis1)\n",
    "    dis2 = LeakyReLU(alpha=leakyrelu_alpha)(dis2)\n",
    "    dis2 = BatchNormalization(momentum=momentum)(dis2)\n",
    "\n",
    "    dis3 = Conv2D(filters=128, kernel_size=3, strides=1, padding='same')(dis2)\n",
    "    dis3 = LeakyReLU(alpha=leakyrelu_alpha)(dis3)\n",
    "    dis3 = BatchNormalization(momentum=momentum)(dis3)\n",
    "\n",
    "    dis4 = Conv2D(filters=128, kernel_size=3, strides=2, padding='same')(dis3)\n",
    "    dis4 = LeakyReLU(alpha=leakyrelu_alpha)(dis4)\n",
    "    dis4 = BatchNormalization(momentum=0.8)(dis4)\n",
    "\n",
    "    dis5 = Conv2D(256, kernel_size=3, strides=1, padding='same')(dis4)\n",
    "    dis5 = LeakyReLU(alpha=leakyrelu_alpha)(dis5)\n",
    "    dis5 = BatchNormalization(momentum=momentum)(dis5)\n",
    "\n",
    "    dis6 = Conv2D(filters=256, kernel_size=3, strides=2, padding='same')(dis5)\n",
    "    dis6 = LeakyReLU(alpha=leakyrelu_alpha)(dis6)\n",
    "    dis6 = BatchNormalization(momentum=momentum)(dis6)\n",
    "\n",
    "    dis7 = Conv2D(filters=512, kernel_size=3, strides=1, padding='same')(dis6)\n",
    "    dis7 = LeakyReLU(alpha=leakyrelu_alpha)(dis7)\n",
    "    dis7 = BatchNormalization(momentum=momentum)(dis7)\n",
    "\n",
    "    dis8 = Conv2D(filters=512, kernel_size=3, strides=2, padding='same')(dis7)\n",
    "    dis8 = LeakyReLU(alpha=leakyrelu_alpha)(dis8)\n",
    "    dis8 = BatchNormalization(momentum=momentum)(dis8)\n",
    "    \n",
    "    # fully connected layer \n",
    "    dis9 = Dense(units=1024)(dis8)\n",
    "    dis9 = LeakyReLU(alpha=0.2)(dis9)\n",
    "    \n",
    "    # last fully connected layer - for classification \n",
    "    output = Dense(units=1, activation='sigmoid')(dis9)   \n",
    "    \n",
    "    model = Model(inputs=[input_layer], outputs=[output], name='discriminator')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2203f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=common_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a05333",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19_base = VGG19(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "def build_VGG19():\n",
    "    input_shape = (128, 128, 3)\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_conv4').output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115faf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_model = build_VGG19()\n",
    "fe_model.trainable = False\n",
    "fe_model.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adversarial_model(generator, discriminator, feature_extractor):\n",
    "    \n",
    "    # input layer for high-resolution images\n",
    "    input_high_resolution = Input(shape=high_resolution_shape)\n",
    "\n",
    "    # input layer for low-resolution images\n",
    "    input_low_resolution = Input(shape=low_resolution_shape)\n",
    "\n",
    "    # generate high-resolution images from low-resolution images\n",
    "    generated_high_resolution_images = generator(input_low_resolution)\n",
    "\n",
    "    # extract feature maps from generated images\n",
    "    features = feature_extractor(generated_high_resolution_images)\n",
    "    \n",
    "    # make a discriminator non-trainable \n",
    "    discriminator.trainable = False\n",
    "    discriminator.compile(loss='mse', optimizer=common_optimizer, metrics=['accuracy'])\n",
    "\n",
    "    # discriminator will give us a probability estimation for the generated high-resolution images\n",
    "    probs = discriminator(generated_high_resolution_images)\n",
    "\n",
    "    # create and compile \n",
    "    adversarial_model = Model([input_low_resolution, input_high_resolution], [probs, features])\n",
    "    adversarial_model.compile(loss=['binary_crossentropy', 'mse'], loss_weights=[1e-3, 1], optimizer=common_optimizer)\n",
    "    \n",
    "    return adversarial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b576d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_model = build_adversarial_model(generator, discriminator, fe_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize \n",
    "\n",
    "losses = {\"d_history\":[], \"g_history\":[]}\n",
    "psnr = {'psnr_quality': []}\n",
    "ssim = {'ssim_quality': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fe1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def upscale_images(images, size):\n",
    "    upscaled_images = []\n",
    "    for img in images:\n",
    "        upscaled_images.append(resize(img, size))\n",
    "    return np.array(upscaled_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a09b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Set up paths\n",
    "data_dir = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "output_dir = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/Downsized_32x32x3'\n",
    "\n",
    "# Define image size\n",
    "img_size = (32, 32)\n",
    "\n",
    "# Loop through train and test folders\n",
    "for folder in [train_dir, test_dir]:\n",
    "\n",
    "    # Loop through DME and DRUSEN subfolders\n",
    "    for subfolder in ['DME', 'DRUSEN']:\n",
    "\n",
    "        # Set up subfolder path\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "\n",
    "        # Loop through images in subfolder\n",
    "        for img_name in os.listdir(subfolder_path):\n",
    "\n",
    "            # Read in image and resize to img_size\n",
    "            img_path = os.path.join(subfolder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_resized = cv2.resize(img, img_size)\n",
    "\n",
    "            # Save resized image to output directory\n",
    "            output_path = os.path.join(output_dir, folder.split('/')[-1], subfolder, img_name)\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            cv2.imwrite(output_path, img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Set up paths\n",
    "data_dir = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "output_dir = '/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/Downsized_128x128x3'\n",
    "\n",
    "# Define image size\n",
    "img_size = (128, 128)\n",
    "\n",
    "# Loop through train and test folders\n",
    "for folder in [train_dir, test_dir]:\n",
    "\n",
    "    # Loop through DME and DRUSEN subfolders\n",
    "    for subfolder in ['DME', 'DRUSEN']:\n",
    "\n",
    "        # Set up subfolder path\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "\n",
    "        # Loop through images in subfolder\n",
    "        for img_name in os.listdir(subfolder_path):\n",
    "\n",
    "            # Read in image and resize to img_size\n",
    "            img_path = os.path.join(subfolder_path, img_name)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_resized = cv2.resize(img, img_size)\n",
    "\n",
    "            # Save resized image to output directory\n",
    "            output_path = os.path.join(output_dir, folder.split('/')[-1], subfolder, img_name)\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            cv2.imwrite(output_path, img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879a0798",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_resolution_shape = (32, 32, 3)\n",
    "high_resolution_shape = (128, 128, 3)\n",
    "batch_size = 8\n",
    "epochs = 150\n",
    "\n",
    "d_history = []\n",
    "g_history = []\n",
    "psnr = {'psnr_quality': []}\n",
    "ssim = {'ssim_quality': []}\n",
    "losses = {'d_history': [], 'g_history': []}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    d_history = []\n",
    "    g_history = []\n",
    "    \n",
    "    image_list = get_train_images(data_path)\n",
    "    \n",
    "    \"\"\"\n",
    "    Train the discriminator network\n",
    "    \"\"\"\n",
    "    \n",
    "    hr_images, lr_images = sample_images(image_list, \n",
    "                                         batch_size=batch_size,\n",
    "                                         high_resolution_shape=(128, 128, 3),\n",
    "                                         low_resolution_shape=(32, 32, 3))\n",
    "                                         \n",
    "    \n",
    "    # generate high-resolution images from low-resolution images\n",
    "    generated_high_resolution_images = generator.predict(lr_images)\n",
    "    generated_high_resolution_images = upscale_images(generated_high_resolution_images, size=(128, 128))\n",
    "    \n",
    "    # normalize the images\n",
    "    hr_images = hr_images / 127.5 - 1.\n",
    "    generated_high_resolution_images = generated_high_resolution_images / 127.5 - 1.\n",
    "    \n",
    "    # generate a batch of true and fake labels \n",
    "    real_labels = np.ones((batch_size, 8, 8, 1))\n",
    "    fake_labels = np.zeros((batch_size, 8, 8, 1))\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch(hr_images, real_labels)\n",
    "    d_loss_real =  np.mean(d_loss_real)\n",
    "    d_loss_fake = discriminator.train_on_batch(generated_high_resolution_images, fake_labels)\n",
    "    d_loss_fake =  np.mean(d_loss_fake)\n",
    "    \n",
    "    # calculate total loss of discriminator as average loss on true and fake labels\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    losses['d_history'].append(d_loss)\n",
    "   \n",
    "\n",
    "    \"\"\"\n",
    "        Train the generator network\n",
    "    \"\"\"\n",
    "      \n",
    "    # sample a batch of images    \n",
    "    hr_images, lr_images = sample_images(image_list, \n",
    "                                         batch_size=batch_size,\n",
    "                                         low_resolution_shape=(32, 32, 3),\n",
    "                                         high_resolution_shape=(128, 128, 3))\n",
    "    \n",
    "    # generate high-resolution images from low-resolution images\n",
    "    generated_high_resolution_images = generator.predict(lr_images)\n",
    "    generated_high_resolution_images = upscale_images(generated_high_resolution_images, size=(128, 128))\n",
    "    \n",
    "    # normalize the images\n",
    "    hr_images = hr_images / 127.5 - 1.\n",
    "    lr_images = lr_images / 127.5 - 1.\n",
    "    generated_high_resolution_images = generated_high_resolution_images / 127.5 - 1.\n",
    "    \n",
    "    # extract feature maps for true high-resolution images\n",
    "    image_features = fe_model.predict(hr_images)\n",
    "\n",
    "    # train the generator\n",
    "    g_loss = adversarial_model.train_on_batch([lr_images, hr_images],\n",
    "                                               [real_labels, image_features])\n",
    "    \n",
    "    losses['g_history'].append(0.5 * (g_loss[1]))\n",
    "    \n",
    "    # calculate the psnr  \n",
    "    ps = compute_psnr(hr_images, generated_high_resolution_images) \n",
    "    psnr['psnr_quality'].append(ps)\n",
    "            \n",
    "    # calculate the ssim \n",
    "    ss = compute_ssim(hr_images, generated_high_resolution_images)   \n",
    "    ssim['ssim_quality'].append(ss)\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "        save and print image samples\n",
    "    \"\"\"\n",
    "    \n",
    "    image_counter = 0\n",
    "\n",
    "    # Save and print image samples\n",
    "    if epoch % 10 == 0:\n",
    "        image_batch_hr, image_batch_lr = sample_images(image_list, 16, high_resolution_shape, low_resolution_shape)\n",
    "\n",
    "        # Normalize the images\n",
    "        image_batch_hr = image_batch_hr / 127.5 - 1.\n",
    "        image_batch_lr = image_batch_lr / 127.5 - 1.\n",
    "\n",
    "        generated_images = generator.predict_on_batch(image_batch_lr)\n",
    "\n",
    "        for index, img in enumerate(generated_images):\n",
    "        # Increment the image counter\n",
    "            image_counter += 1\n",
    "\n",
    "            # Name the generated image using the epoch and index values\n",
    "            image_name = \"generated_image_e{}_{}.png\".format(epoch, index)\n",
    "\n",
    "            # Save the generated image in the \"Generated Images\" folder\n",
    "            save_images(image_batch_hr[index], image_batch_lr[index], img, path=\"/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Data/Generated Images/{}\".format(image_name))\n",
    "            \n",
    "    \"\"\"\n",
    "        save the generator and discriminator .h5 files every 10 epoch\n",
    "    \"\"\"\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        # Save the generator model as .h5 file\n",
    "        generator.save('/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Generator_Epochs/generator_model_epoch_{}.h5'.format(epoch))\n",
    "\n",
    "        # Save the discriminator model as .h5 file\n",
    "        discriminator.save('/home/jsmith/Desktop/JohnSmith_AssignmentMidtermProject/Discriminator_Epochs/discriminator_model_epoch_{}.h5'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6352fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
